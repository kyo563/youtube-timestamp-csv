import streamlit as st
import re
import csv
import io
import requests
import urllib.parse
from typing import Tuple, List, Optional

st.set_page_config(page_title="ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—CSVã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼", layout="centered")

st.title("ğŸµ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—CSVã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
st.write(
    "YouTubeå‹•ç”»ã®URLã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒªã‚¹ãƒˆã‹ã‚‰CSVã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
    "å‡ºåŠ›ã¯ **ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå / æ¥½æ›²å / YouTubeãƒªãƒ³ã‚¯** ã®3åˆ—å›ºå®šã§ã€"
    "ãƒªãƒ³ã‚¯åˆ—ã¯å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤ºã®ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯ã«ãªã‚Šã¾ã™ã€‚"
    "CSVã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰åã‚‚å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã«è‡ªå‹•è¨­å®šã—ã¾ã™ï¼ˆUTF-8 BOMï¼‰ã€‚"
)

# ------------------------------
# å…¥åŠ›UI
# ------------------------------
url = st.text_input("1. YouTubeå‹•ç”»ã®URL", placeholder="https://www.youtube.com/watch?v=xxxxxxxxxxx")
timestamps = st.text_area(
    "2. æ¥½æ›²ãƒªã‚¹ãƒˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰",
    placeholder="ä¾‹ï¼š\n0:35 æ¥½æ›²åA - ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåA\n6:23 æ¥½æ›²åB / ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåB\n1:10:05 ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåCã€Œæ¥½æ›²åCã€",
    height=220,
    key="timestamps_input",
)

# ------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ------------------------------
def is_valid_youtube_url(u: str) -> bool:
    pattern = re.compile(r"^(https?:\/\/)?(www\.)?(youtube\.com|youtu\.?be)\/.+$")
    return bool(pattern.match(u or ""))

def extract_video_id(u: str) -> Optional[str]:
    """URLã‹ã‚‰Video IDã‚’é ‘å¥ã«æŠ½å‡ºï¼ˆwatch?v= / youtu.be / shorts/ ã«å¯¾å¿œï¼‰ã€‚"""
    if not u:
        return None
    try:
        pr = urllib.parse.urlparse(u)
        host = (pr.netloc or "").lower()
        path = pr.path or ""
        qs = urllib.parse.parse_qs(pr.query or "")

        # https://youtu.be/<id>
        if "youtu.be" in host:
            seg = path.strip("/").split("/")
            return seg[0] if seg and seg[0] else None

        # https://www.youtube.com/watch?v=<id>
        if "youtube.com" in host:
            if "v" in qs and qs["v"]:
                return qs["v"][0]
            # https://www.youtube.com/shorts/<id>
            if path.startswith("/shorts/"):
                after = path.split("/shorts/", 1)[1]
                return after.split("/")[0].split("?")[0]
        return None
    except Exception:
        return None

def normalize_text(s: str) -> str:
    """å…¨è§’â†’åŠè§’ãªã©è»½å¾®ãªæ­£è¦åŒ–ã€‚ä½™è¨ˆãªç©ºç™½ã‚’æ•´ç†ã€‚"""
    s = (s or "").replace("ï¼", "/").replace("â€“", "-").replace("â€•", "-").replace("ãƒ¼", "-")
    s = s.replace("ã€€", " ").strip()
    return re.sub(r"\s+", " ", s)

def parse_line(line: str) -> Tuple[Optional[int], Optional[str], Optional[str]]:
    """
    å…ˆé ­ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª­ã¿å–ã‚Šã€(seconds, artist, song) ã‚’è¿”ã—ã¾ã™ã€‚
    è§£æä¸å¯ãªã‚‰ (None, None, None) ã‚’è¿”ã—ã¾ã™ã€‚
    """
    m = re.match(r"^(\d{1,2}:)?(\d{1,2}):(\d{2})", line)
    if not m:
        return (None, None, None)

    time_str = m.group(0)
    parts = list(map(int, time_str.split(":")))
    if len(parts) == 3:
        seconds = parts[0] * 3600 + parts[1] * 60 + parts[2]
    else:
        seconds = parts[0] * 60 + parts[1]

    info = line[len(time_str):].strip()

    # å¼•ç”¨ï¼ˆã€Œã€/ã€ã€/â€œâ€/"ï¼‰ã§æ›²åãŒå›²ã¾ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹
    quote = re.search(r'[ã€Œã€â€œ"](.+?)[ã€ã€â€"]', info)
    if quote:
        song = quote.group(1).strip()
        artist = (info[:quote.start()] + info[quote.end():]).strip(" -/byBy")
        artist = normalize_text(artist)
        return (seconds, artist if artist else "N/A", song if song else "N/A")

    # åŒºåˆ‡ã‚Šå€™è£œ
    seps = [" - ", " â€” ", " / ", " by ", " BY ", "/"]
    for sep in seps:
        if sep in info:
            left, right = info.split(sep, 1)
            left, right = left.strip(), right.strip()
            # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆå¤šã„æ–¹ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã¨ä»®å®šï¼ˆç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰
            alpha_left = len(re.findall(r"[A-Za-z]", left))
            alpha_right = len(re.findall(r"[A-Za-z]", right))
            if alpha_left > alpha_right:
                artist, song = left, right
            else:
                artist, song = right, left
            return (seconds, normalize_text(artist) or "N/A", normalize_text(song) or "N/A")

    # åŒºåˆ‡ã‚ŠãŒãªã„å ´åˆï¼šå…¨æ–‡ã‚’æ›²åæ‰±ã„
    return (seconds, "N/A", normalize_text(info) or "N/A")

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_video_title_from_oembed(watch_url: str) -> str:
    """oEmbedã§å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰ã€‚å¤±æ•—æ™‚ã¯æ—¢å®šåã€‚"""
    try:
        r = requests.get(
            "https://www.youtube.com/oembed",
            params={"url": watch_url, "format": "json"},
            timeout=6
        )
        if r.status_code == 200:
            title = (r.json().get("title") or "").strip()
            return title if title else "YouTubeå‹•ç”»"
    except Exception:
        pass
    return "YouTubeå‹•ç”»"

def make_hyperlink_formula(url_: str, display_text: str) -> str:
    """Excelç”¨ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯å¼ã€‚ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã€‚"""
    safe_title = (display_text or "").replace('"', '""')
    return f'=HYPERLINK("{url_}","{safe_title}")'

def make_safe_filename(name: str, ext: str = ".csv") -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’ç½®æ›ã—ã€é•·ã•ã‚‚åˆ¶é™ã€‚"""
    name = re.sub(r'[\\/\:\*\?"<>\|\x00-\x1F]', "_", (name or ""))
    name = name.strip().strip(".")
    if not name:
        name = "youtube_song_list"
    if len(name) > 100:
        name = name[:100]
    return f"{name}{ext}"

def to_csv(rows: List[List[str]]) -> str:
    out = io.StringIO()
    writer = csv.writer(out, quoting=csv.QUOTE_ALL)
    writer.writerows(rows)
    return out.getvalue()

# ------------------------------
# ä¸»å‡¦ç†ï¼šCSVè¡Œç”Ÿæˆï¼ˆ3åˆ—å›ºå®šï¼‰
# ------------------------------
def generate_rows(u: str, ts: str) -> Tuple[List[List[str]], List[dict], List[str], str]:
    vid = extract_video_id(u)
    if not vid:
        raise ValueError("URLã‹ã‚‰ãƒ“ãƒ‡ã‚ªIDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    base_watch = f"https://www.youtube.com/watch?v={vid}"
    video_title = fetch_video_title_from_oembed(base_watch)

    # ãƒ˜ãƒƒãƒ€ã¯3åˆ—å›ºå®š
    rows: List[List[str]] = [["ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå", "æ¥½æ›²å", "YouTubeãƒªãƒ³ã‚¯"]]
    parsed_preview = []
    invalid_lines = []

    for raw in (ts or "").splitlines():
        line = normalize_text(raw)
        if not line:
            continue
        sec, artist, song = parse_line(line)
        if sec is None:
            invalid_lines.append(raw)
            continue

        jump = f"{base_watch}&t={sec}s"
        hyperlink = make_hyperlink_formula(jump, video_title)
        rows.append([artist, song, hyperlink])

        parsed_preview.append({
            "time_seconds": sec,
            "artist": artist,
            "song": song,
            "hyperlink_formula": hyperlink,
        })

    if len(rows) == 1:
        raise ValueError("æœ‰åŠ¹ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    return rows, parsed_preview, invalid_lines, video_title

# ------------------------------
# ãƒœã‚¿ãƒ³ç¾¤
# ------------------------------
c1, c2 = st.columns(2)

with c1:
    if st.button("ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º"):
        if not url or not timestamps:
            st.error("URLã¨æ¥½æ›²ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not is_valid_youtube_url(url):
            st.error("æœ‰åŠ¹ãªYouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            try:
                rows, preview, invalid, video_title = generate_rows(url, timestamps)
                st.success(f"è§£ææˆåŠŸï¼š{len(preview)}ä»¶ã€‚æœªè§£æï¼š{len(invalid)}ä»¶ã€‚")
                if preview:
                    import pandas as pd
                    df = pd.DataFrame(preview)
                    st.dataframe(df, use_container_width=True)
                st.caption(f"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼š{video_title}")
                if invalid:
                    with st.expander("æœªè§£æè¡Œã®ä¸€è¦§"):
                        st.code("\n".join(invalid))
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

with c2:
    if st.button("ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"):
        if not url or not timestamps:
            st.error("URLã¨æ¥½æ›²ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not is_valid_youtube_url(url):
            st.error("æœ‰åŠ¹ãªYouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            try:
                rows, preview, invalid, video_title = generate_rows(url, timestamps)
                csv_content = to_csv(rows)

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰åï¼šå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆï¼‰
                download_name = make_safe_filename(video_title, ".csv")

                st.success("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
                st.download_button(
                    label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_content.encode("utf-8-sig"),
                    file_name=download_name,
                    mime="text/csv"
                )
                if invalid:
                    st.info(f"æœªè§£æè¡Œï¼š{len(invalid)}ä»¶ã€‚å…¥åŠ›ã®æ›¸å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# ------------------------------
# ãƒ˜ãƒ«ãƒ—
# ------------------------------
with st.expander("ğŸ‘€ ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›ã®ãƒ’ãƒ³ãƒˆ"):
    st.markdown("- URLä¾‹: `https://www.youtube.com/watch?v=dQw4w9WgXcQ`")
    st.markdown("- è¡Œæ›¸å¼: `MM:SS` ã¾ãŸã¯ `HH:MM:SS` + åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ + ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆåŒºåˆ‡ã‚Š `-`, `/`, `by`, å¼•ç”¨ã€Œã€ ãªã©ï¼‰")
