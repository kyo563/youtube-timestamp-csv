import streamlit as st
import re
import csv
import io
import requests
import urllib.parse
from datetime import datetime, timezone
from typing import Tuple, List, Optional, Dict
from zoneinfo import ZoneInfo

# ==============================
# åŸºæœ¬è¨­å®š
# ==============================
st.set_page_config(page_title="YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—CSVã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼", layout="centered")

st.title("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—CSVã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
st.write(
    "YouTubeå‹•ç”»ã®URLã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒªã‚¹ãƒˆã‹ã‚‰CSVã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
    "å‡ºåŠ›ã¯ **ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå / æ¥½æ›²å / YouTubeãƒªãƒ³ã‚¯** ã®3åˆ—å›ºå®šã§ã™ã€‚"
    "ãƒªãƒ³ã‚¯åˆ—ã®è¡¨ç¤ºåã¯ **å…¬é–‹æ—¥(yyyymmdd) + å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«** ã§ã™ï¼ˆAPIã‚­ãƒ¼æœªè¨­å®šæ™‚ã¯æ‰‹å‹•å…¥åŠ›å¯ï¼‰ã€‚"
)

# è¡¨ç¤ºåã®åŒºåˆ‡ã‚Šï¼ˆä¾‹: 20250101 My Video Titleï¼‰
DATE_TITLE_SEPARATOR = " "
# ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã¯å›ºå®šï¼ˆUIã«å‡ºã•ãªã„ï¼‰
TZ_NAME = "Asia/Tokyo"

# ==============================
# å…¥åŠ›UI
# ==============================
url = st.text_input("1. YouTubeå‹•ç”»ã®URL", placeholder="https://www.youtube.com/watch?v=xxxxxxxxxxx")

# APIã‚­ãƒ¼ï¼ˆSecretså„ªå…ˆã€æœªè¨­å®šãªã‚‰ä»»æ„å…¥åŠ›ï¼‰
API_KEY = st.secrets.get("YT_API_KEY", "")
if not API_KEY:
    with st.expander("YouTube APIã‚­ãƒ¼ï¼ˆä»»æ„ã€‚æœªè¨­å®šã§ã‚‚æ‰‹å‹•ã§å…¬é–‹æ—¥ã‚’æŒ‡å®šã§ãã¾ã™ï¼‰"):
        API_KEY = st.text_input("YT_API_KEY", type="password")

# APIæœªä½¿ç”¨æ™‚ã®æ‰‹å‹•å…¬é–‹æ—¥ï¼ˆ8æ¡ï¼‰
manual_date = ""
if not API_KEY:
    manual_date = st.text_input("å…¬é–‹æ—¥ (yyyymmdd) ã‚’æ‰‹å‹•æŒ‡å®šï¼ˆAPIæœªè¨­å®šæ™‚ã«åˆ©ç”¨ï¼ä»»æ„ï¼‰", placeholder="ä¾‹: 20250101")

# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å…¥åŠ›ï¼ˆå¿…ãš session_state ã¨åŒæœŸï¼‰
timestamps_input = st.text_area(
    "2. æ¥½æ›²ãƒªã‚¹ãƒˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰",
    placeholder="ä¾‹ï¼š\n0:35 æ¥½æ›²åA - ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåA\n6:23 æ¥½æ›²åB / ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåB\n1:10:05 ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåCã€Œæ¥½æ›²åCã€",
    height=220,
    key="timestamps_input",
)

# ==============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼šä¸€èˆ¬
# ==============================
def is_valid_youtube_url(u: str) -> bool:
    return bool(re.match(r"^(https?:\/\/)?(www\.)?(youtube\.com|youtu\.?be)\/.+$", u or ""))

def extract_video_id(u: str) -> Optional[str]:
    """URLã‹ã‚‰Video IDã‚’æŠ½å‡ºï¼ˆwatch?v= / youtu.be / shorts/ ã«å¯¾å¿œï¼‰ã§ã™ã€‚"""
    if not u:
        return None
    try:
        pr = urllib.parse.urlparse(u)
        host = (pr.netloc or "").lower()
        path = pr.path or ""
        qs = urllib.parse.parse_qs(pr.query or "")
        if "youtu.be" in host:
            seg = path.strip("/").split("/")
            return seg[0] if seg and seg[0] else None
        if "youtube.com" in host:
            if "v" in qs and qs["v"]:
                return qs["v"][0]
            if path.startswith("/shorts/"):
                after = path.split("/shorts/", 1)[1]
                return after.split("/")[0].split("?")[0]
        return None
    except Exception:
        return None

def normalize_text(s: str) -> str:
    """å…¨è§’â†’åŠè§’ãªã©è»½å¾®ãªæ­£è¦åŒ–ã¨ç©ºç™½æ•´å½¢ã§ã™ã€‚â€»ä¼¸ã°ã—æ£’ã€Œãƒ¼ã€ã¯å¤‰æ›ã—ã¾ã›ã‚“ã€‚"""
    s = (s or "").replace("ï¼", "/")   # å…¨è§’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã®ã¿åŠè§’ã¸
    s = s.replace("ã€€", " ").strip()  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹â†’åŠè§’
    return re.sub(r"\s+", " ", s)     # é€£ç¶šç©ºç™½ã‚’1ã¤ã«

def parse_line(line: str) -> Tuple[Optional[int], Optional[str], Optional[str]]:
    """
    å…ˆé ­ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª­ã¿å–ã‚Šã€(seconds, artist, song) ã‚’è¿”ã—ã¾ã™ã€‚
    è§£æä¸å¯ãªã‚‰ (None, None, None) ã‚’è¿”ã—ã¾ã™ã€‚
    """
    m = re.match(r"^(\d{1,2}:)?(\d{1,2}):(\d{2})", line)
    if not m:
        return (None, None, None)
    time_str = m.group(0)
    parts = list(map(int, time_str.split(":")))
    seconds = parts[0] * 3600 + parts[1] * 60 + parts[2] if len(parts) == 3 else parts[0] * 60 + parts[1]
    info = line[len(time_str):].strip()

    # å¼•ç”¨ï¼ˆã€Œã€/ã€ã€/â€œâ€/"ï¼‰ã§æ›²åãŒå›²ã¾ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹
    quote = re.search(r'[ã€Œã€â€œ"](.+?)[ã€ã€â€"]', info)
    if quote:
        song = quote.group(1).strip()
        artist = (info[:quote.start()] + info[quote.end():]).strip(" -/byBy")
        artist = normalize_text(artist)
        return (seconds, artist if artist else "N/A", song if song else "N/A")

    # åŒºåˆ‡ã‚Šï¼šå‰å¾Œã«ç©ºç™½ãŒã‚ã‚‹è¨˜å·/èªï¼ˆãƒ¼ã¯åŒºåˆ‡ã‚Šæ‰±ã„ã—ãªã„ï¼‰
    # å¯¾è±¡: -, â€”, â€“, â€•, ï¼, /, ï¼, by, BY
    msep = re.search(r"\s(-|â€”|â€“|â€•|ï¼|/|ï¼|by|BY)\s", info)
    if msep:
        left = info[:msep.start()].strip()
        right = info[msep.end():].strip()
        # ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼šã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆå¤šã„æ–¹ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ
        alpha_left = len(re.findall(r"[A-Za-z]", left))
        alpha_right = len(re.findall(r"[A-Za-z]", right))
        if alpha_left > alpha_right:
            artist, song = left, right
        else:
            artist, song = right, left
        return (seconds, normalize_text(artist) or "N/A", normalize_text(song) or "N/A")

    # åŒºåˆ‡ã‚ŠãŒãªã„å ´åˆï¼šå…¨æ–‡ã‚’æ›²åæ‰±ã„
    return (seconds, "N/A", normalize_text(info) or "N/A")

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_video_title_from_oembed(watch_url: str) -> str:
    """oEmbedã§å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰ã€‚å¤±æ•—æ™‚ã¯æ—¢å®šåã€‚"""
    try:
        r = requests.get("https://www.youtube.com/oembed", params={"url": watch_url, "format": "json"}, timeout=6)
        if r.status_code == 200:
            title = (r.json().get("title") or "").strip()
            return title if title else "YouTubeå‹•ç”»"
    except Exception:
        pass
    return "YouTubeå‹•ç”»"

# ==============================
# æ—¥ä»˜ï¼šãƒ©ã‚¤ãƒ–/ãƒ—ãƒ¬ãƒŸã‚¢å„ªå…ˆ + ãƒ­ãƒ¼ã‚«ãƒ«TZå¤‰æ›ï¼ˆTZ_NAMEã§å›ºå®šï¼‰
# ==============================
def _iso_utc_to_tz_yyyymmdd(iso_str: str, tz_name: str) -> Optional[str]:
    """ISO8601(UTC,'Z') â†’ tz_name ã¸å¤‰æ›ã— yyyymmdd ã‚’è¿”ã—ã¾ã™ã€‚"""
    if not iso_str:
        return None
    try:
        dt_utc = datetime.strptime(iso_str, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=timezone.utc)
        dt_local = dt_utc.astimezone(ZoneInfo(tz_name))
        return dt_local.strftime("%Y%m%d")
    except Exception:
        return None

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_best_display_date_and_sources(video_id: str, api_key: str, tz_name: str) -> Dict[str, Optional[str]]:
    """
    videos?part=snippet,liveStreamingDetails ã‚’å–å¾—ã€‚
    å„ªå…ˆé †ä½: actualStartTime â†’ scheduledStartTime â†’ publishedAtã€‚
    ãã‚Œãã‚Œã‚’ tz_name ã¸å¤‰æ›ã—ãŸ yyyymmdd ã¨æ¡ç”¨ã‚½ãƒ¼ã‚¹ã‚’è¿”ã™ã€‚
    """
    result = {
        "chosen_yyyymmdd": None,
        "source": None,  # "actualStartTime" | "scheduledStartTime" | "publishedAt" | "manual"
    }
    if not api_key:
        return result
    try:
        url = "https://www.googleapis.com/youtube/v3/videos"
        params = {"part": "snippet,liveStreamingDetails", "id": video_id, "key": api_key}
        r = requests.get(url, params=params, timeout=6)
        if r.status_code != 200:
            return result
        items = (r.json() or {}).get("items", [])
        if not items:
            return result

        item = items[0]
        snippet = item.get("snippet", {}) or {}
        live = item.get("liveStreamingDetails", {}) or {}

        publishedAt = snippet.get("publishedAt")
        actualStartTime = live.get("actualStartTime")
        scheduledStartTime = live.get("scheduledStartTime")

        publishedAt_local = _iso_utc_to_tz_yyyymmdd(publishedAt, tz_name) if publishedAt else None
        actualStartTime_local = _iso_utc_to_tz_yyyymmdd(actualStartTime, tz_name) if actualStartTime else None
        scheduledStartTime_local = _iso_utc_to_tz_yyyymmdd(scheduledStartTime, tz_name) if scheduledStartTime else None

        if actualStartTime_local:
            result["chosen_yyyymmdd"] = actualStartTime_local
            result["source"] = "actualStartTime"
        elif scheduledStartTime_local:
            result["chosen_yyyymmdd"] = scheduledStartTime_local
            result["source"] = "scheduledStartTime"
        elif publishedAt_local:
            result["chosen_yyyymmdd"] = publishedAt_local
            result["source"] = "publishedAt"

        return result
    except Exception:
        return result

# ==============================
# CSVé–¢é€£ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==============================
def make_hyperlink_formula(url_: str, display_text: str) -> str:
    """Excelç”¨ HYPERLINK é–¢æ•°æ–‡å­—åˆ—ã€‚"""
    safe = (display_text or "").replace('"', '""')
    return f'=HYPERLINK("{url_}","{safe}")'

def make_safe_filename(name: str, ext: str = ".csv") -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚º + é•·ã•åˆ¶é™ã€‚"""
    name = re.sub(r'[\\/:*?"<>|\x00-\x1F]', "_", name or "").strip().strip(".")
    if not name:
        name = "youtube_song_list"
    if len(name) > 100:
        name = name[:100]
    return f"{name}{ext}"

def to_csv(rows: List[List[str]]) -> str:
    out = io.StringIO()
    csv.writer(out, quoting=csv.QUOTE_ALL).writerows(rows)
    return out.getvalue()

# ==============================
# ä¸»å‡¦ç†ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼CSVã§å…±é€šåˆ©ç”¨ï¼‰
# ==============================
def generate_rows(u: str, timestamps_text: str, tz_name: str, api_key: str, manual_yyyymmdd: str) -> Tuple[List[List[str]], List[dict], List[str], str]:
    """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã€CSVè¡Œãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡Œãƒ»æœªè§£æè¡Œãƒ»å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿”ã—ã¾ã™ã€‚"""
    vid = extract_video_id(u)
    if not vid:
        raise ValueError("URLã‹ã‚‰ãƒ“ãƒ‡ã‚ªIDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    base_watch = f"https://www.youtube.com/watch?v={vid}"

    # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆoEmbedï¼‰
    video_title = fetch_video_title_from_oembed(base_watch)

    # æ—¥ä»˜ï¼ˆãƒ©ã‚¤ãƒ–/ãƒ—ãƒ¬ãƒŸã‚¢å„ªå…ˆ + ãƒ­ãƒ¼ã‚«ãƒ«TZå¤‰æ›ï¼‰
    date_info = {"chosen_yyyymmdd": None, "source": None}
    if api_key:
        date_info = fetch_best_display_date_and_sources(vid, api_key, tz_name)

    date_yyyymmdd: Optional[str] = date_info.get("chosen_yyyymmdd")
    date_source: Optional[str] = date_info.get("source")

    # APIã§å–å¾—ä¸å¯ãƒ»æœªè¨­å®šæ™‚ã¯æ‰‹å‹•æ—¥ä»˜
    if not date_yyyymmdd and manual_yyyymmdd and re.fullmatch(r"\d{8}", manual_yyyymmdd):
        date_yyyymmdd = manual_yyyymmdd
        date_source = "manual"

    display_name = f"{date_yyyymmdd}{DATE_TITLE_SEPARATOR}{video_title}" if date_yyyymmdd else video_title

    # ãƒ˜ãƒƒãƒ€ã¯3åˆ—å›ºå®š
    rows: List[List[str]] = [["ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå", "æ¥½æ›²å", "YouTubeãƒªãƒ³ã‚¯"]]
    parsed_preview: List[dict] = []
    invalid_lines: List[str] = []

    for raw in (timestamps_text or "").splitlines():
        line = normalize_text(raw)
        if not line:
            continue
        sec, artist, song = parse_line(line)
        if sec is None:
            invalid_lines.append(raw)
            continue

        jump = f"{base_watch}&t={sec}s"
        hyperlink = make_hyperlink_formula(jump, display_name)
        rows.append([artist, song, hyperlink])
        parsed_preview.append({
            "time_seconds": sec,
            "artist": artist,
            "song": song,
            "display_name": display_name,
            "date_source": date_source,
            "hyperlink_formula": hyperlink,
        })

    if len(rows) == 1:
        raise ValueError("æœ‰åŠ¹ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    return rows, parsed_preview, invalid_lines, video_title

# ==============================
# ãƒœã‚¿ãƒ³ç¾¤ï¼ˆã©ã¡ã‚‰ã‚‚ session_state ã‚’ä½¿ç”¨ï¼‰
# ==============================
c1, c2 = st.columns(2)

with c1:
    if st.button("ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º"):
        timestamps_text = st.session_state.get("timestamps_input", "")
        if not url or not timestamps_text:
            st.error("URLã¨æ¥½æ›²ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not is_valid_youtube_url(url):
            st.error("æœ‰åŠ¹ãªYouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            try:
                rows, preview, invalid, video_title = generate_rows(url, timestamps_text, TZ_NAME, API_KEY, manual_date)
                st.success(f"è§£ææˆåŠŸï¼š{len(preview)}ä»¶ã€‚æœªè§£æï¼š{len(invalid)}ä»¶ã€‚")
                if preview:
                    import pandas as pd
                    st.dataframe(pd.DataFrame(preview), use_container_width=True)
                st.caption(f"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼š{video_title}")
                if invalid:
                    with st.expander("æœªè§£æè¡Œã®ä¸€è¦§"):
                        st.code("\n".join(invalid))
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

with c2:
    if st.button("ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"):
        timestamps_text = st.session_state.get("timestamps_input", "")
        if not url or not timestamps_text:
            st.error("URLã¨æ¥½æ›²ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not is_valid_youtube_url(url):
            st.error("æœ‰åŠ¹ãªYouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            try:
                rows, preview, invalid, video_title = generate_rows(url, timestamps_text, TZ_NAME, API_KEY, manual_date)
                csv_content = to_csv(rows)
                download_name = make_safe_filename(video_title, ".csv")

                st.success("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
                st.download_button(
                    label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_content.encode("utf-8-sig"),  # BOMä»˜ãUTF-8ï¼ˆExceläº’æ›ï¼‰
                    file_name=download_name,
                    mime="text/csv"
                )
                if invalid:
                    st.info(f"æœªè§£æè¡Œï¼š{len(invalid)}ä»¶ã€‚å…¥åŠ›ã®æ›¸å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# ==============================
# ãƒ˜ãƒ«ãƒ—
# ==============================
with st.expander("ğŸ‘€ ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›ã®ãƒ’ãƒ³ãƒˆ"):
    st.markdown("- URLä¾‹: `https://www.youtube.com/watch?v=dQw4w9WgXcQ`")
    st.markdown("- è¡Œæ›¸å¼: `MM:SS` ã¾ãŸã¯ `HH:MM:SS` + åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ + ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆåŒºåˆ‡ã‚Š ` - `, ` / `, ` by ` ãªã©ã€‚ä¼¸ã°ã—æ£’ã€Œãƒ¼ã€ã¯åŒºåˆ‡ã‚Šæ‰±ã„ã—ã¾ã›ã‚“ï¼‰")
    st.markdown("- æ—¥ä»˜ã‚½ãƒ¼ã‚¹å„ªå…ˆåº¦: **actualStartTime â†’ scheduledStartTime â†’ publishedAt â†’ æ‰‹å‹•**ï¼ˆUTCâ†’Tokyoã«å¤‰æ›ï¼‰ã€‚")
