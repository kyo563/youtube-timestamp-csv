import streamlit as st
import re
import csv
import io
import requests
import urllib.parse
from datetime import datetime
from typing import Tuple, List, Optional

st.set_page_config(page_title="YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—CSVã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼", layout="centered")

st.title("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—CSVã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
st.write(
    "YouTubeå‹•ç”»ã®URLã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒªã‚¹ãƒˆã‹ã‚‰CSVã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
    "å‡ºåŠ›ã¯ **ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå / æ¥½æ›²å / YouTubeãƒªãƒ³ã‚¯** ã®3åˆ—å›ºå®šã§ã™ã€‚"
    "ãƒªãƒ³ã‚¯åˆ—ã®è¡¨ç¤ºåã¯ **å…¬é–‹æ—¥(yyyymmdd)+å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«** ã«ãªã‚Šã¾ã™ï¼ˆAPIã‚­ãƒ¼æœªè¨­å®šæ™‚ã¯æ‰‹å‹•å…¥åŠ›å¯ï¼‰ã€‚"
)

# è¡¨ç¤ºåã®åŒºåˆ‡ã‚Šã‚’ã€Œ+ã€ã«å›ºå®šï¼ˆä¾‹: 20250101+My Video Titleï¼‰
DATE_TITLE_SEPARATOR = " "

# ------------------------------
# å…¥åŠ›UI
# ------------------------------
url = st.text_input("1. YouTubeå‹•ç”»ã®URL", placeholder="https://www.youtube.com/watch?v=xxxxxxxxxxx")

# APIã‚­ãƒ¼ï¼ˆSecretså„ªå…ˆã€æœªè¨­å®šãªã‚‰ä»»æ„ã§æ‰‹å‹•å…¥åŠ›ï¼‰
API_KEY = st.secrets.get("YT_API_KEY", "")
if not API_KEY:
    with st.expander("YouTube APIã‚­ãƒ¼ï¼ˆä»»æ„ã€‚æœªè¨­å®šã§ã‚‚æ‰‹å‹•ã§å…¬é–‹æ—¥ã‚’æŒ‡å®šã§ãã¾ã™ï¼‰"):
        API_KEY = st.text_input("YT_API_KEY", type="password")

# APIæœªä½¿ç”¨æ™‚ã®æ‰‹å‹•å…¬é–‹æ—¥ï¼ˆ8æ¡ï¼‰
manual_date = ""
if not API_KEY:
    manual_date = st.text_input("å…¬é–‹æ—¥ (yyyymmdd) ã‚’æ‰‹å‹•æŒ‡å®šï¼ˆAPIæœªè¨­å®šæ™‚ã«åˆ©ç”¨ï¼ä»»æ„ï¼‰", placeholder="ä¾‹: 20250101")

timestamps = st.text_area(
    "2. æ¥½æ›²ãƒªã‚¹ãƒˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰",
    placeholder="ä¾‹ï¼š\n0:35 æ¥½æ›²åA - ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåA\n6:23 æ¥½æ›²åB / ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåB\n1:10:05 ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåCã€Œæ¥½æ›²åCã€",
    height=220,
    key="timestamps_input",
)

# ------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ------------------------------
def is_valid_youtube_url(u: str) -> bool:
    pattern = re.compile(r"^(https?:\/\/)?(www\.)?(youtube\.com|youtu\.?be)\/.+$")
    return bool(pattern.match(u or ""))

def extract_video_id(u: str) -> Optional[str]:
    """URLã‹ã‚‰Video IDã‚’æŠ½å‡ºï¼ˆwatch?v= / youtu.be / shorts/ ã«å¯¾å¿œï¼‰ã§ã™ã€‚"""
    if not u:
        return None
    try:
        pr = urllib.parse.urlparse(u)
        host = (pr.netloc or "").lower()
        path = pr.path or ""
        qs = urllib.parse.parse_qs(pr.query or "")

        # https://youtu.be/<id>
        if "youtu.be" in host:
            seg = path.strip("/").split("/")
            return seg[0] if seg and seg[0] else None

        # https://www.youtube.com/watch?v=<id>
        if "youtube.com" in host:
            if "v" in qs and qs["v"]:
                return qs["v"][0]
            # https://www.youtube.com/shorts/<id>
            if path.startswith("/shorts/"):
                after = path.split("/shorts/", 1)[1]
                return after.split("/")[0].split("?")[0]
        return None
    except Exception:
        return None

def normalize_text(s: str) -> str:
    """å…¨è§’â†’åŠè§’ãªã©è»½å¾®ãªæ­£è¦åŒ–ã¨ç©ºç™½æ•´å½¢ã§ã™ã€‚â€»ä¼¸ã°ã—æ£’ã€Œãƒ¼ã€ã¯å¤‰æ›ã—ã¾ã›ã‚“ã€‚"""
    s = (s or "").replace("ï¼", "/")   # å…¨è§’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã®ã¿åŠè§’ã¸
    s = s.replace("ã€€", " ").strip()  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹â†’åŠè§’
    return re.sub(r"\s+", " ", s)     # é€£ç¶šç©ºç™½ã‚’1ã¤ã«

def parse_line(line: str) -> Tuple[Optional[int], Optional[str], Optional[str]]:
    """
    å…ˆé ­ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª­ã¿å–ã‚Šã€(seconds, artist, song) ã‚’è¿”ã—ã¾ã™ã€‚
    è§£æä¸å¯ãªã‚‰ (None, None, None) ã‚’è¿”ã—ã¾ã™ã€‚
    """
    m = re.match(r"^(\d{1,2}:)?(\d{1,2}):(\d{2})", line)
    if not m:
        return (None, None, None)

    time_str = m.group(0)
    parts = list(map(int, time_str.split(":")))
    if len(parts) == 3:
        seconds = parts[0] * 3600 + parts[1] * 60 + parts[2]
    else:
        seconds = parts[0] * 60 + parts[1]

    info = line[len(time_str):].strip()

    # å¼•ç”¨ï¼ˆã€Œã€/ã€ã€/â€œâ€/"ï¼‰ã§æ›²åãŒå›²ã¾ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹
    quote = re.search(r'[ã€Œã€â€œ"](.+?)[ã€ã€â€"]', info)
    if quote:
        song = quote.group(1).strip()
        artist = (info[:quote.start()] + info[quote.end():]).strip(" -/byBy")
        artist = normalize_text(artist)
        return (seconds, artist if artist else "N/A", song if song else "N/A")

    # åŒºåˆ‡ã‚Šï¼šå‰å¾Œã«ç©ºç™½ãŒã‚ã‚‹è¨˜å·/èªã®ã¿ï¼ˆãƒ¼ã¯åŒºåˆ‡ã‚Šã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰
    # å¯¾è±¡: -, â€”, â€“, â€•, ï¼, /, ï¼, by, BY
    msep = re.search(r"\s(-|â€”|â€“|â€•|ï¼|/|ï¼|by|BY)\s", info)
    if msep:
        left = info[:msep.start()].strip()
        right = info[msep.end():].strip()
        # ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼šã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆå¤šã„æ–¹ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ
        alpha_left = len(re.findall(r"[A-Za-z]", left))
        alpha_right = len(re.findall(r"[A-Za-z]", right))
        if alpha_left > alpha_right:
            artist, song = left, right
        else:
            artist, song = right, left
        return (seconds, normalize_text(artist) or "N/A", normalize_text(song) or "N/A")

    # åŒºåˆ‡ã‚ŠãŒãªã„å ´åˆï¼šå…¨æ–‡ã‚’æ›²åæ‰±ã„
    return (seconds, "N/A", normalize_text(info) or "N/A")

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_video_title_from_oembed(watch_url: str) -> str:
    """oEmbedã§å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰ã§ã™ã€‚å¤±æ•—æ™‚ã¯æ—¢å®šåã§ã™ã€‚"""
    try:
        r = requests.get(
            "https://www.youtube.com/oembed",
            params={"url": watch_url, "format": "json"},
            timeout=6
        )
        if r.status_code == 200:
            title = (r.json().get("title") or "").strip()
            return title if title else "YouTubeå‹•ç”»"
    except Exception:
        pass
    return "YouTubeå‹•ç”»"

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_published_yyyymmdd(video_id: str, api_key: str) -> Optional[str]:
    """YouTube Data API v3ã§å…¬é–‹æ—¥ã‚’å–å¾—ã— yyyymmdd ã§è¿”ã—ã¾ã™ï¼ˆAPIã‚­ãƒ¼å¿…é ˆï¼‰ã€‚"""
    if not api_key:
        return None
    try:
        url = "https://www.googleapis.com/youtube/v3/videos"
        params = {"part": "snippet", "id": video_id, "key": api_key}
        r = requests.get(url, params=params, timeout=6)
        if r.status_code != 200:
            return None
        items = (r.json() or {}).get("items", [])
        if not items:
            return None
        publishedAt = items[0].get("snippet", {}).get("publishedAt", "")
        # ä¾‹: 2020-01-02T03:04:05Z
        dt = datetime.strptime(publishedAt, "%Y-%m-%dT%H:%M:%SZ")
        return dt.strftime("%Y%m%d")
    except Exception:
        return None

def make_hyperlink_formula(url_: str, display_text: str) -> str:
    """Excelç”¨ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯å¼ã§ã™ã€‚ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¾ã™ã€‚"""
    safe = (display_text or "").replace('"', '""')
    return f'=HYPERLINK("{url_}","{safe}")'

def make_safe_filename(name: str, ext: str = ".csv") -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’ç½®æ›ã—ã€é•·ã•ã‚‚åˆ¶é™ã—ã¾ã™ã€‚"""
    name = re.sub(r'[\\/:*?"<>|\x00-\x1F]', "_", name or "")
    name = name.strip().strip(".")
    if not name:
        name = "youtube_song_list"
    if len(name) > 100:
        name = name[:100]
    return f"{name}{ext}"

def to_csv(rows: List[List[str]]) -> str:
    out = io.StringIO()
    writer = csv.writer(out, quoting=csv.QUOTE_ALL)
    writer.writerows(rows)
    return out.getvalue()

# ------------------------------
# ä¸»å‡¦ç†ï¼šCSVè¡Œç”Ÿæˆï¼ˆ3åˆ—å›ºå®šï¼‰
# ------------------------------
def generate_rows(u: str, ts: str) -> Tuple[List[List[str]], List[dict], List[str], str]:
    vid = extract_video_id(u)
    if not vid:
        raise ValueError("URLã‹ã‚‰ãƒ“ãƒ‡ã‚ªIDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    base_watch = f"https://www.youtube.com/watch?v={vid}"

    # ã‚¿ã‚¤ãƒˆãƒ«
    video_title = fetch_video_title_from_oembed(base_watch)

    # å…¬é–‹æ—¥ï¼ˆAPIãŒã‚ã‚Œã°è‡ªå‹•ã€ãªã‘ã‚Œã°æ‰‹å‹•ï¼‰
    date_yyyymmdd: Optional[str] = None
    if API_KEY:
        date_yyyymmdd = fetch_published_yyyymmdd(vid, API_KEY)
    if not date_yyyymmdd and manual_date and re.fullmatch(r"\d{8}", manual_date):
        date_yyyymmdd = manual_date

    # è¡¨ç¤ºåï¼ˆå…¬é–‹æ—¥ãŒå–ã‚ŒãŸå ´åˆã¯å…ˆé ­ã«ä»˜ä¸: yyyymmdd+ã‚¿ã‚¤ãƒˆãƒ«ï¼‰
    if date_yyyymmdd:
        display_name = f"{date_yyyymmdd}{DATE_TITLE_SEPARATOR}{video_title}"
    else:
        display_name = video_title  # å–å¾—ã§ããªã‘ã‚Œã°ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿

    # ãƒ˜ãƒƒãƒ€ã¯3åˆ—å›ºå®š
    rows: List[List[str]] = [["ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå", "æ¥½æ›²å", "YouTubeãƒªãƒ³ã‚¯"]]
    parsed_preview = []
    invalid_lines = []

    for raw in (ts or "").splitlines():
        line = normalize_text(raw)
        if not line:
            continue
        sec, artist, song = parse_line(line)
        if sec is None:
            invalid_lines.append(raw)
            continue

        jump = f"{base_watch}&t={sec}s"
        hyperlink = make_hyperlink_formula(jump, display_name)
        rows.append([artist, song, hyperlink])

        parsed_preview.append({
            "time_seconds": sec,
            "artist": artist,
            "song": song,
            "display_name": display_name,
            "hyperlink_formula": hyperlink,
        })

    if len(rows) == 1:
        raise ValueError("æœ‰åŠ¹ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    return rows, parsed_preview, invalid_lines, video_title

# ------------------------------
# ãƒœã‚¿ãƒ³ç¾¤
# ------------------------------
c1, c2 = st.columns(2)

with c1:
    if st.button("ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º"):
        if not url or not timestamps:
            st.error("URLã¨æ¥½æ›²ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not is_valid_youtube_url(url):
            st.error("æœ‰åŠ¹ãªYouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            try:
                rows, preview, invalid, video_title = generate_rows(url, timestamps)
                st.success(f"è§£ææˆåŠŸï¼š{len(preview)}ä»¶ã€‚æœªè§£æï¼š{len(invalid)}ä»¶ã€‚")
                if preview:
                    import pandas as pd
                    df = pd.DataFrame(preview)
                    st.dataframe(df, use_container_width=True)
                st.caption(f"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼š{video_title}")
                if invalid:
                    with st.expander("æœªè§£æè¡Œã®ä¸€è¦§"):
                        st.code("\n".join(invalid))
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

with c2:
    if st.button("ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"):
        if not url or not timestamps:
            st.error("URLã¨æ¥½æ›²ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not is_valid_youtube_url(url):
            st.error("æœ‰åŠ¹ãªYouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            try:
                rows, preview, invalid, video_title = generate_rows(url, timestamps)
                csv_content = to_csv(rows)

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰åï¼šå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆï¼‰
                download_name = make_safe_filename(video_title, ".csv")

                st.success("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
                st.download_button(
                    label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_content.encode("utf-8-sig"),
                    file_name=download_name,
                    mime="text/csv"
                )
                if invalid:
                    st.info(f"æœªè§£æè¡Œï¼š{len(invalid)}ä»¶ã€‚å…¥åŠ›ã®æ›¸å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# ------------------------------
# ãƒ˜ãƒ«ãƒ—
# ------------------------------
with st.expander("ğŸ‘€ ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›ã®ãƒ’ãƒ³ãƒˆ"):
    st.markdown("- URLä¾‹: `https://www.youtube.com/watch?v=dQw4w9WgXcQ`")
    st.markdown("- è¡Œæ›¸å¼: `MM:SS` ã¾ãŸã¯ `HH:MM:SS` + åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ + ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆåŒºåˆ‡ã‚Š ` - `, ` / `, ` by ` ãªã©ã€‚ä¼¸ã°ã—æ£’ã€Œãƒ¼ã€ã¯åŒºåˆ‡ã‚Šæ‰±ã„ã—ã¾ã›ã‚“ï¼‰")
